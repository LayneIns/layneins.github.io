
<!DOCTYPE html>
<html>

<style>
/*body {
  margin-top: 30px;
  margin-bottom: 30px;
  margin-left: 30px;
  margin-right:30px;
}*/
a {text-decoration : none; color : #003399;}
a:hover {text-decoration:underline; color: #8C1515; }
.content {
  max-width: 800px;
  margin-top: 10px;
  margin-bottom: 30px;
  margin-left: auto;
  margin-right: auto;
}
html *{
  font-family: Avenir
}
.bib-content {
  font-family: STKaiti
}

.tab-links {
  display: flex;
  align-items: center;
  gap: 15px; /* Distance between tabs */
  margin-bottom: 20px;
  font-size: 16px;
}

.separator {
  font-weight: normal; /* Keep separator weight normal */
  font-size: 16px;
  color: #000;
}

</style>

<style>
.disabled{
    pointer-events: none;
    color:black;
}

</style>

<script>
function copy(dest, source) {
  if(dest.source == source) {
    dest.innerHTML = "";
    dest.source = null;
  }
  else {
    dest.innerHTML = source.innerHTML;
    dest.source = source;
  }
  dest.blur();
}

function toggleSection(sectionId) {
  const section = document.getElementById(sectionId);
  const allSections = ['preprint-section', 'year-2025-section', 'year-2024-section', 'year-2023-and-before-section'];
  
  if (section) {
    const isCurrentlyVisible = section.style.display !== 'none';
    
    // Check if other sections are shown
    const otherSectionsVisible = allSections.some(id => {
      if (id !== sectionId) {
        const otherSection = document.getElementById(id);
        return otherSection && otherSection.style.display !== 'none';
      }
      return false;
    });
    
    // Firstly hide all other sections
    allSections.forEach(id => {
      if (id !== sectionId) {
        const otherSection = document.getElementById(id);
        if (otherSection) {
          otherSection.style.display = 'none';
        }
      }
    });
    
    // If current section is shown and no other sections are shown，then hide the current section
    // If current section is hidden，or if there are other shown sections，then show the current section
    if (isCurrentlyVisible && !otherSectionsVisible) {
      section.style.display = 'none';
    } else {
      section.style.display = 'block';
    }
  }
}

function toggleAll() {
  const sections = ['preprint-section', 'year-2025-section', 'year-2024-section', 'year-2023-and-before-section'];
  const allVisible = sections.every(id => {
    const section = document.getElementById(id);
    return section && section.style.display !== 'none';
  });
  
  sections.forEach(id => {
    const section = document.getElementById(id);
    if (section) {
      section.style.display = allVisible ? 'none' : 'block';
    }
  });
}

// Default Status: show all content
window.addEventListener('DOMContentLoaded', function() {
  const sections = ['preprint-section', 'year-2025-section', 'year-2024-section', 'year-2023-and-before-section'];
  sections.forEach(id => {
    const section = document.getElementById(id);
    if (section) {
      section.style.display = 'block';
    }
  });
});
</script>

<head>
    <title>Hui's Homepage</title>
    <link rel="icon" href="icons/lico.jpg">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="./icons/css/academicons.min.css"/>
    <script src="https://kit.fontawesome.com/3e1c7539c7.js" crossorigin="anonymous"></script>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="author" content="Hui Liu">
    <meta name="keywords" content="Hui Liu">
    <meta name="robots" content="index,follow">
    <meta name="description" content="Homepage of Hui Liu.">
</head>

<body style="width:80%;" class="content">

<table cellpadding="20" style="font-size: 17px">
<tr>
<td><img src='photo/img4.jpg' alt="Hui Liu"/, height = 250></td>
<td>
<h1> Hui Liu <span style="font-family:STKaiti; font-size:18pt"> (刘晖)</span> </h1>
<!-- <font size="+1"><b>Ph.D. Candidate </b> in <b>Computer Science</b> <br><b>XXXX University</b> <br> <br> -->
<b>Email</b>: <a href="mailto:&#104;&#117;&#105;&#108;&#105;&#117;&#108;&#97;&#121;&#110;&#101;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;"><tt>&#104;&#117;&#105;&#108;&#105;&#117;&#108;&#97;&#121;&#110;&#101;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;</tt></a> <br>
<!-- <b>Office</b>: XXXX</font> <br> -->
<br>
<!-- <a href = "#education">[Education]</a>  -->
<a href = "#publications">[Publications]</a>
<!-- <a href = "#experience">[Experience]</a> -->
<!-- <a href = "#services">[Services]</a> -->
<a href="#misc">[Miscellaneous]</a> <br> <br>
<!-- <a href="files/CV.pdf" title="CV"><i class="ai ai-cv-square ai-2x"></i></a> -->
<a href="https://scholar.google.com/citations?user=brfcskMAAAAJ" title="Google Scholar" target="_blank"><i class="ai ai-google-scholar-square ai-2x"></i></a>
<!-- <a href="https://twitter.com/layneliuhui" title="Twitter"><i class="fab fa-twitter-square ai-2x"></i></a> -->
<!-- <a href="https://github.com/LayneIns" title="GitHub" target="_blank"><i class="fab fa-github-square ai-2x"></i></a> -->
<a href="https://www.linkedin.com/in/hui-liu-702990155/" title="LinkedIn" target="_blank"><i class="fab fa-linkedin ai-2x"></i>
<!-- <a href="personalstatement/ps.mp4">[A vedio of personal statement]</a> -->
</td>
<!-- <td><img src='', height = 100></td> -->
</tr>
</table>


<!-- <a name = "about" class="disabled"><h2> About Me </h2></a> -->
<h2> About Me </h2></a>
<p>
  Hi! My name is Hui Liu. I am a Senior Applied Scientist at Amazon Ads. I obtained my Ph.D. degree from the <a href="https://www.ece.queensu.ca">Department of Electrical and Computer Engineering</a> at <a href="https://www.queensu.ca" target="_blank">Queen's University</a>. 
  <!-- My advisor is <a href="http://www.xiaodanzhu.com">Prof. Xiaodan Zhu</a>.  -->
  Prior to that, I received my B.S. from the <a href = "http://eecs.pku.edu.cn/" target="_blank">School of Electronics Engineering and Computer Science </a> at <a href = "http://www.pku.edu.cn" target="_blank"> Peking University</a> in 2018. <br>
</p>

Back in my third year of undergrad, when I was tinkering with SVMs for my first research project, I could never have imagined witnessing the shift in natural language processing from RNNs to Transformers. Now I feel fortunate to witness the impressive power of LLMs driving the new trends in NLP research. Recently, the question I think a lot is - <i>what is reasoning?</i> 

<!-- <span style="color: red;">** We are hiring interns! If you are interested in working with us, please feel free to reach out or email me with your resume.</span> -->
<!-- <br><br> -->
      
<!-- <a name = "news" class="disabled"><h2> News </h2></a> -->
<h2 style="margin-top: 30px;"> News </h2></a>
<p>
  <!-- <div style="height:180px;border:1px solid #ccc;font:16px/26px Georgia, Garamond, Serif;overflow:auto;" id="news-content"> -->
  <div style="border:1px solid #ccc;font:16px/26px Georgia, Garamond, Serif;overflow:auto;" id="news-content">
    <ul>
      <li><span style="color: blue">[2025.10]</span> I will serve as a senior PC member at WWW 2026.</li>
      <li><span style="color: blue">[2025.10]</span> Our paper "SFT or RL? An Early Investigation into Training R1-Like Reasoning Large Vision-Language Models" is accept to TMLR! Please check out the paper <a href="https://arxiv.org/abs/2504.11468" target="_blank">here</a>.</li>
      <li><span style="color: blue">[2025.09]</span> Two papers, on agent test-time scaling and LLM unlearning, accepted to NeurIPS 2025! Thanks for our interns and collaborators!</li>
      <li><span style="color: blue">[2025.08]</span> Four papers accepted to EMNLP 2025! Thanks for our interns and collaborators!</li>
      <li><span style="color: blue">[2025.06]</span> We are releasing a preview of <a href="https://github.com/Wu-Zongyu/CharmBench" target="_blank">CharmBench</a>, a challenging reasoning and multimodal benchmark for large vision-language models. Please feel free to test your VLMs based on the preview and reach out to us for any suggestions and feedbacks!</li>
      <!-- <li><span style="color: blue">[2025.06]</span> Our paper "In-Context Personalized Alignment with Feedback History under Counterfactual Evaluation" is accepted to ICML 2025 Workshop on Models of Human Feedback for AI Alignment (MoFA)! Thanks for our intern and collaborators!</li> -->
      <!-- <li><span style="color: blue">[2025.05]</span> We have 5 papers accepted to ACL 2025! Thanks for our interns and collaborators!</li> -->
      <!-- <li><span style="color: blue">[2025.05]</span> We will host a "<a href="https://kdd2025llm4ecommerce.github.io" target="_blank">Large Language Model for E-Commerce</a>" Workshop at KDD'25! We invite <a href="https://openreview.net/group?id=KDD.org/2025/Workshop/LLM4ECommerce" target="_blank">submissions</a> that contribute to advancing the state-of-the-art in LLMs for e-commerce.</li> -->
      <!-- <li><span style="color: blue">[2025.05]</span> Our paper "Mitigating Heterogeneous Token Overfitting in LLM Knowledge Editing" is accepted to ICML 2025! Thanks for our intern and collaborators!</li> -->
      <!-- <li><span style="color: blue">[2025.04]</span> Our paper "Examples as the Prompt: A Scalable Approach for Efficient LLM Adaptation in E-Commerce" is accepted to SIGIR 2025 SIRIP (Industry Track) track! </li> -->
      <!-- <li><span style="color: blue">[2025.01]</span> Two papers accepted to ICLR 2025! Thanks for our interns and collaborators!</li> -->
      <!-- <li><span style="color: blue">[2025.01]</span> Three papers accepted to NAACL 2025! Thanks for our interns and collaborators!</li> -->
      <!-- <li><span style="color: blue">[2024.10]</span> Our paper “Exploring Query Understanding for Amazon Product Search” is accepted to IEEE BigData'24.</li> -->
      <!-- <li><span style="color: blue">[2023.10]</span> Our paper “Knowledge-Selective Pretraining for Attribute Value Extraction” is accepted to the Findings of EMNLP 2023 as a long paper. Thanks for the collaborators from Amazon!</li> -->
      <!-- <li><span style="color: blue">[2023.09]</span> Start to be an Applied Scientist at Amazon Search. </li> -->
      <!-- <li><span style="color: blue">[2022.09]</span> Start to be an Applied Scientist Intern at Amazon. </li> -->
      <!-- <li><span style="color: blue">[2021.12]</span> Our paper “Interpretable Low-Resource Legal Decision Making” is accepted to AAAI 2022 AI for Social Impact Track. <span style="color: red">[NEW]</span> </li> -->
      <!-- <li><span style="color: blue">[2021.08]</span> Our paper “Unsupervised Conversation Disentanglement through Co-Training” is accepted to EMNLP 2021 main conference.<span style="color: red">[NEW]</span> </li> -->
      <!-- <li><span style="color: blue">[2021.08]</span> Our paper “Retrieval, Analogy, and Composition: A framework for Compositional Generalization in Image Captioning” is accepted to Findings of EMNLP 2021. <span style="color: red">[NEW]</span> </li> -->
      <!-- <li><span style="color: blue">[2021.05]</span> Our paper “Enhancing Descriptive Image Captioning with Natural Language Inference” is accepted to ACL 2021 main conference.</li> -->
      <!-- <li><span style="color: blue">[2021.04]</span> Our paper “Partner Matters! An Empirical Study on Fusing Personas for Personalized Response Selection in Retrieval-Based Chatbots” is accepted to SIGIR 2021.</li> -->
      <!-- <li><span style="color: blue">[2021.03]</span> Our paper “Improving Pretrained Models for Zero-shot Multi-label Text Classification through Reinforced Label Hierarchy Reasoning” accepted to NAACL-HLT 2021. Thanks for the collaborators at Amazon!</li> -->
      <!-- <li><span style="color: blue">[2021.02]</span> Our paper “Have You Made A Decision? Where? A Pilot Study on Interpretability of Polarity Analysis Based on Advising Problem” accepted to ICASSP 2021.</li> -->
      <!-- <li><span style="color: blue">[2020.07]</span> Start to be an applied scientist intern at Amazon</li> -->
      <!-- <li><span style="color: blue">[2020.04]</span> Our paper “End-to-End Transition-Based Online Dialogue Disentanglement” accepted to IJCAI 2020</li> -->
      <!-- <li><span style="color: blue">[2020.03]</span> This summer, I will join the Search Science and AI group at Amazon as an applied scientist intern</li> -->
      <!-- <li><span style="color: blue">[2019.09]</span> Start as a PhD student at Queen’s University</li> -->
      <!-- <li><span style="color: blue">[2019.07]</span> Start my research internship at <a href="https://www.iflytek.com/index.html">iFLYTEK</a> research group</li> -->
      <!-- <li><span style="color: blue">[2019.05]</span> Our paper “Towards Explainable NLP: A Generative Explanation Framework for Text Classification” accepted to ACL 2019</li> -->
      <!-- <li><span style="color: blue">[2018.11]</span> I will be a research assistant at the <a href="https://lit.eecs.umich.edu/">Language and Information Technologies (LIT) Group</a>, University of Michigan, Ann Arbor (with <a href="https://web.eecs.umich.edu/~mihalcea/">Prof. Rada Mihalcea</a>)</li>
      <li><span style="color: blue">[2018.07]</span> Start my summer internship as a research assistant at the <a href="http://nlp.cs.ucsb.edu/">NLP Group</a>, University of California, Santa Barbara (with <a href="https://sites.cs.ucsb.edu/~william/">Prof. William Wang</a>)</li>
      <li><span style="color: blue">[2018.06]</span> Graduate from Peking University. See you PKU!</li> -->
    </ul>
  </div>
</p>

<!-- <a name = "experience" class="disabled"><h2>Experience </h2></a> -->
<h2 style="margin-top: 30px;">Experience </h2></a>
<ul>
  <li>
    <p>
      <b>2023.09 - Present: Amazon</b>
      <br>
      Senior Applied Scientist
    </p>
  </li>
  <li>
    <p>
      <b>2020.07 - 2020.11 & 2022.09 - 2022.12: Amazon Search Query Understanding Team</b>
      <br>
      Applied Scientist Intern
    </p>
  </li>
  <!-- <li>
    <p>
      <b>2018.11 - 2019.05: <a href="http://lit.eecs.umich.edu/" target="_blank">Language and Information Technologies Group, University of Michigan</a></b>
      <br>
      Research Assistant, with <a href="https://web.eecs.umich.edu/~mihalcea/index.html" target="_blank">Prof. Rada Mihalcea</a>
    </p>
  </li>
  <li>
    <p>
      <b>2018.07 - 2018.09: <a href="http://nlp.cs.ucsb.edu/" target="_blank">NLP Group, UC Santa Barbara</a></b>
      <br> 
      Research Intern, with <a href="https://www.cs.ucsb.edu/~william/" target="_blank">Prof. William Wang</a>
    </p>
  </li> -->
  <li>
    <p>
      <b>2018.01 - 2018.05: Lenovo AI Lab, Beijing </b>
      <br>
      Research Intern
    </p>
  </li>
</ul>

<h2 style="margin-top: 30px;">Academic Services </h2></a>
<ul>
  <li>
    <b>Area Chair</b>: EMNLP (2024-2025), NAACL (2025), ACL (2025)
  </li>
  <li>
    <b>Senior Program Committee</b>: WWW (2026)
  </li>
  <li>
    <b>Program Committee</b>: ACL (2022-2024), EMNLP (2021-2024), NAACL (2024), EACL (2023), ICLR (2022-2026), NeurIPS (2022-2025), ICML (2023-2025), COLM (2024-2025), AAAI (2022-2024), KDD (2025)
  </li>
  <li>
    I am also a regular Area Chair for <a href="https://aclrollingreview.org" target="_blank">ACL Rolling Review</a>.
  </li>
</ul>


<a name = "publications" class="disabled" style="color: inherit; text-decoration: none; pointer-events: none;"><h2 style="margin-top: 30px;"> Publication/Preprint</h2></a>

<div class="tab-links">
[
  <a href="javascript:void(0)" onclick="toggleAll()">All</a>
  <span class="separator">|</span>
  <a href="javascript:void(0)" onclick="toggleSection('year-2025-section')">2025</a>
  <span class="separator">|</span>
  <a href="javascript:void(0)" onclick="toggleSection('year-2024-section')">2024</a>
  <span class="separator">|</span>
  <a href="javascript:void(0)" onclick="toggleSection('year-2023-and-before-section')">2023 and before</a>
  <span class="separator">|</span>
  <a href="javascript:void(0)" onclick="toggleSection('preprint-section')">Preprint</a>
]
</div>

<ol>
  <div id="year-2025-section">
  <h3 id="year-2025">2025</h3>
  <li>
    <b>
      <a href="https://arxiv.org/abs/2504.11468" target="_blank">SFT or RL? An Early Investigation into Training R1-Like Reasoning Large Vision-Language Models</a> 
    </b>
    <br>
    Hardy Chen, Haoqin Tu, Fali Wang, <b>Hui Liu</b>, Xianfeng Tang, Xinya Du, Yuyin Zhou, Cihang Xie
    <br>
    <i>Transactions on Machine Learning Research (TMLR), 2025</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2508.00890" target="_blank">AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks</a> 
    </b>
    <br>
    Fali Wang, <b>Hui Liu</b>, Zhenwei Dai, Jingying Zeng, Zhiwei Zhang, Zongyu Wu, Chen Luo, Zhen Li, Xianfeng Tang, Qi He, Suhang Wang
    <br>
    <i>NeurIPS 2025</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2506.00359" target="_blank">Keeping an Eye on LLM Unlearning: The Hidden Risk and Remedy</a> 
    </b>
    <br>
    Jie Ren, Zhenwei Dai, Xianfeng Tang, Yue Xing, Shenglai Zeng, <b>Hui Liu</b>, Jingying Zeng, Qiankun Peng, Samarth Varshney, Suhang Wang, Qi He, Charu C Aggarwal, Hui Liu
    <br>
    <i>NeurIPS 2025</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2506.17265" target="_blank">Does Multimodal Large Language Model Truly Unlearn? Stealthy MLLM Unlearning Attack</a> 
    </b>
    <br>
    Xianren Zhang, <b>Hui Liu</b>, Delvin Ce Zhang, Xianfeng Tang, Qi He, Dongwon Lee, Suhang Wang
    <br>
    <i>EMNLP 2025, long paper</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2505.13957" target="_blank">Beyond Text: Unveiling Privacy Vulnerabilities in Multi-modal Retrieval-Augmented Generation</a> 
    </b>
    <br>
    Jiankun Zhang, Shenglai Zeng, Jie Ren, Tianqi Zheng, <b>Hui Liu</b>, Xianfeng Tang, Hui Liu, Yi Chang
    <br>
    <i>EMNLP 2025, long paper</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2503.20271" target="_blank">ViLBench: A Suite for Vision-Language Process Reward Modeling</a> 
    </b>
    <br>
    Haoqin Tu, Weitao Feng, Hardy Chen, <b>Hui Liu</b>, Xianfeng Tang, Cihang Xie
    <br>
    <i>EMNLP 2025, long paper</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://openreview.net/forum?id=m0ddLnNvXS" target="_blank">Automatic Task-aware Instruction Optimizer for Black-box LLMs</a> 
    </b>
    <br>
    Yunzhe Qi, Jinjin Tian, Ruirui Li, Tianci Liu, Tianxin Wei, <b>Hui Liu</b>, Xianfeng Tang, Monica Xiao Cheng, Jingrui He
    <br>
    <i>Findings of EMNLP 2025, long paper</i>
  </li>
  <br>

  <li>
    <b>
      <a href="" target="_self">In-Context Personalized Alignment with Feedback History under Counterfactual Evaluation</a> 
    </b>
    <br>
    Xisen Jin, Zheng Li, Zhenwei DAI, <b>Hui Liu</b>, Xianfeng Tang, Chen Luo, Rahul Goutam, Xiang Ren, Qi He
    <br>
    <i>ICML 2025 MoFA Workshop, long paper</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2505.15196" target="_blank">EcomScriptBench: A Multi-task Benchmark for E-commerce Script Planning via Step-wise Intention-Driven Product Association</a> 
    </b>
    <br>
    Weiqi Wang, Limeng Cui, Xin Liu, Sreyashi Nag, Wenju Xu, Chen Luo, Sheikh Muhammad Sarwar, Yang Li, Hansu Gu, <b>Hui Liu</b>, Changlong Yu, Jiaxin Bai, Yifan Gao, Haiyang Zhang, Qi He, Shuiwang Ji, Yangqiu Song
    <br>
    <i>ACL 2025, long paper</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2502.13260" target="_blank">Stepwise Perplexity-Guided Refinement for Efficient Chain-of-Thought Reasoning in Large Language Models</a> 
    </b>
    <br>
    Yingqian Cui, Pengfei He, Jingying Zeng, <b>Hui Liu</b>, Xianfeng Tang, Zhenwei Dai, Yan Han, Chen Luo, Jing Huang, Zhen Li, Suhang Wang, Yue Xing, Jiliang Tang, Qi He
    <br>
    <i>Findings of ACL 2025, long paper</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2410.12207" target="_blank">Divide-Verify-Refine: Aligning LLM Responses with Complex Instructions</a> 
    </b>
    <br>
    Xianren Zhang, Xianfeng Tang, <b>Hui Liu</b>, Zongyu Wu, Qi He, Dongwon Lee, Suhang Wang
    <br>
    <i>Findings of ACL 2025, long paper</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2501.07845" target="_blank">Reasoning with Graphs: Structuring Implicit Knowledge to Enhance LLMs Reasoning</a> 
    </b>
    <br>
    Haoyu Han, Yaochen Xie, <b>Hui Liu</b>, Xianfeng Tang, Sreyashi Nag, William Headden, Hui Liu, Yang Li, Chen Luo, Shuiwang Ji, Qi He, Jiliang Tang
    <br>
    <i>Findings of ACL 2025, long paper</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2502.17823" target="_blank">A General Framework to Enhance Fine-tuning-based LLM Unlearning</a> 
    </b>
    <br>
    Jie Ren, Zhenwei Dai, Xianfeng Tang, <b>Hui Liu</b>, Jingying Zeng, Zhen Li, Rahul Goutam, Suhang Wang, Yue Xing, Qi He
    <br>
    <i>Findings of ACL 2025, long paper</i>
  </li>
  <br>

  <li>
    <b>
      <a href="#" target="_self">Mitigating Heterogeneous Token Overfitting in LLM Knowledge Editing</a> 
    </b>
    <br>
    Tianci Liu, Ruirui Li, Zihan Dong, <b>Hui Liu</b>, Xianfeng Tang, Qingyu Yin, Linjun Zhang, Haoyu Wang, Jing Gao
    <br>
    <i>ICML 2025</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2503.13518" target="_blank">Examples as the Prompt: A Scalable Approach for Efficient LLM Adaptation in E-Commerce</a> 
    </b>
    <br>
    Jingying Zeng, Zhenwei Dai, <b>Hui Liu</b>, Samarth Varshney, Zhiji Liu, Chen Luo, Zhen Li, Qi He, Xianfeng Tang
    <br>
    <i>SIGIR 2025 SIRIP (Industry Track) track</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://openreview.net/forum?id=lHSeDYamnz" target="_blank">Catastrophic Failure of LLM Unlearning via Quantization</a> 
    </b>
    <br>
    Zhiwei Zhang, Fali Wang, Xiaomin Li, Zongyu Wu, Xianfeng Tang, <b>Hui Liu</b>, Qi He, Wenpeng Yin, Suhang Wang
    <br>
    <i>ICLR 2025</i>
  </li>
  <font size="-1">
    [<a href="https://github.com/zzwjames/FailureLLMUnlearning" target="_blank">code</a>]
    [<a href="https://news.ycombinator.com/item?id=42037982" target="_blank">Hacker News</a>]
  </font>
  <br>

  <li>
    <b>
      <a href="https://openreview.net/forum?id=PITFO1ddeh" target="_blank">Unlocking Efficient, Scalable, and Continual Knowledge Editing with Basis-Level Representation Fine-Tuning</a> 
    </b>
    <br>
    Tianci Liu, Ruirui Li, Haoyu Wang, Yunzhe Qi, <b>Hui Liu</b>, Xianfeng Tang, Tianqi Zheng, Qingyu Yin, Monica Cheng, Jun Huan, Jing Gao 
    <br>
    <i>ICLR 2025</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://aclanthology.org/2025.naacl-long.575/" target="_blank">SimRAG: Self-Improving Retrieval-Augmented Generation for Adapting Large Language Models to Specialized Domains</a> 
    </b>
    <br>
    Ran Xu, <b>Hui Liu</b>, Sreyashi Nag, Zhenwei Dai, Yaochen Xie, Xianfeng Tang, Chen Luo, Yang Li, Joyce C Ho, Carl Yang, Qi He
    <br>
    <i>NAACL 2025, long paper</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://aclanthology.org/2025.naacl-long.151/" target="_blank">Towards Knowledge Checking in Retrieval-augmented Generation: A Representation Perspective</a> 
    </b>
    <br>
    Shenglai Zeng, Jiankun Zhang, Bingheng Li, Yuping Lin, Tianqi Zheng, Dante Everaert, Hanqing Lu, <b>Hui Liu</b>, Hui Liu, Yue Xing, Monica Xiao Cheng, Jiliang Tang
    <br>
    <i>NAACL 2025, long paper</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://aclanthology.org/2025.findings-naacl.142/" target="_blank">Learning with Less: Knowledge Distillation from Large Language Models via Unlabeled Data</a> 
    </b>
    <br>
    Juanhui Li, Sreyashi Nag, <b>Hui Liu</b>, Xianfeng Tang, Sheikh Sarwar, Limeng Cui, Hansu Gu, Suhang Wang, Qi He, Jiliang Tang
    <br>
    <i>Findings of NAACL 2025, long paper</i>
  </li>
  </div>

  <div id="year-2024-section">
  <h3 id="year-2024">2024</h3>
  <li>
    <b>
      <a href="https://arxiv.org/abs/2408.02215" target="_blank">Exploring Query Understanding for Amazon Product Search</a> 
    </b>
    <br>
    Chen Luo, Xianfeng Tang, Hanqing Lu, Yaochen Xie, <b>Hui Liu</b>, Zhenwei Dai, Limeng Cui, Ashutosh Joshi, Sreyashi Nag, Yang Li, Zhen Li, Rahul Goutam, Jiliang Tang, Haiyang Zhang, Qi He
    <br>
    <i>IEEE BigData'24, full paper</i>
  </li>
  </div>

  <div id="year-2023-and-before-section">
  <h3 id="year-2023-and-before">2023 and before</h3>
  <li>
    <b>
      <a href="https://aclanthology.org/2023.findings-emnlp.542/" target="_blank">Knowledge-Selective Pretraining for Attribute Value Extraction</a> 
    </b>
    <br>
    <b>Hui Liu</b>, Qingyu Yin, Zhengyang Wang, Chenwei Zhang, Haoming Jiang, Yifan Gao, Zheng Li, Xian Li, Chao Zhang, Bing Yin, William Yang Wang, Xiaodan Zhu
    <br>
    <i>Findings of EMNLP 2023, long paper</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://ojs.aaai.org/index.php/AAAI/article/view/21438" target="_blank">Interpretable Low-Resource Legal Decision Making</a> 
    </b>
    <br>
    Rohan Bhambhoria, <b>Hui Liu</b>, Samuel Dahan, Xiaodan Zhu
    <br>
    <i>AAAI 2022 AI for Social Impact Track, full paper</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://aclanthology.org/2021.emnlp-main.181/" target="_blank">Unsupervised Conversation Disentanglement through Co-Training</a> 
    </b>
    <br>
    <b>Hui Liu</b>, Zhan Shi, Xiaodan Zhu
    <br>
    <i>EMNLP 2021 main conference, long paper</i>
  </li>
  <font size="-1">
    [<a href="https://github.com/LayneIns/Unsupervised_dialo_disentanglement"  target="_blank">code</a>]
  </font>
  <br>

  <li>
    <b>
      <a href="https://aclanthology.org/2021.findings-emnlp.171/" target="_blank">Retrieval, Analogy, and Composition: A framework for Compositional Generalization in Image Captioning</a> 
    </b>
    <br>
    Zhan Shi, <b>Hui Liu</b>, Martin Renqiang Min, Christopher Malon, Li Erran Li and Xiaodan Zhu
    <br>
    <i>Findings of EMNLP 2021, long paper</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://caiac.pubpub.org/pub/zllzroe5/release/1" target="_blank">Descriptive Image Captioning with Salient Retrieval Priors</a> 
    </b>
    <br>
    Zhan Shi, <b>Hui Liu</b>, Xiaodan Zhu
    <br>
    <i>Canadian Conference on Artificial Intelligence 2021, full paper</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://aclanthology.org/2021.acl-short.36/" target="_blank">Enhancing Descriptive Image Captioning with Natural Language Inference</a> 
    </b>
    <br>
    Zhan Shi, <b>Hui Liu</b>, Xiaodan Zhu
    <br>
    <i>ACL-IJCNLP 2021 main conference, short paper</i>
  </li>
  <font size="-1">
    [<a href="https://github.com/Gitsamshi/Nli-image-caption" target="_blank">code</a>]
  </font>
  <br>

  <li>
    <b>
      <a href="https://dl.acm.org/doi/abs/10.1145/3404835.3462858" target="_blank">Partner Matters! An Empirical Study on Fusing Personas for Personalized Response Selection in Retrieval-Based Chatbots</a> 
    </b>
    <br>
    Jia-Chen Gu, <b>Hui Liu</b>, Zhen-Hua Ling, Quan Liu, Zhigang Chen, Xiaodan Zhu
    <br>
    <i>SIGIR 2021, full paper</i>
  </li>
  <font size="-1">
    [<a href="https://github.com/JasonForJoy/Personalized-Response-Selection" target="_blank">code</a>]
  </font>
  <br>

  <li>
    <b>
      <a href="https://www.aclweb.org/anthology/2021.naacl-main.83/" target="_blank">Improving Pretrained Models for Zero-shot Multi-label Text Classification through Reinforced Label Hierarchy Reasoning</a> 
    </b>
    <br>
    <b>Hui Liu</b>, Danqing Zhang, Bing Yin, Xiaodan Zhu
    <br>
    <i>NAACL-HLT 2021, long paper</i>
  </li>
  <font size="-1">
    [<a href="https://github.com/LayneIns/Zero-shot-RLHR" target="_blank">code</a>]
  </font>
  <br>

  <li>
    <b>
      <a href="https://ieeexplore.ieee.org/document/9413654"  target="_blank">Have You Made A Decision? Where? A Pilot Study on Interpretability of Polarity Analysis Based on Advising Problem</a>
    </b>
    <br> 
    Tianda Li, Jia-Chen Gu, <b>Hui Liu</b>, Quan Liu, Zhen-hua Ling, Zhiming Su, Xiaodan Zhu
    <br>
    <i>ICASSP 2021, full paper</i>
  </li>
  <font size="-1">
    [<a href="https://github.com/TeddLi/UCM" target="_blank">code</a>]
  </font>
  <br>


  <li>
    <b>
      <a href="https://www.ijcai.org/Proceedings/2020/535" target="_blank">End-to-End Transition-Based Online Dialogue Disentanglement</a>
    </b>
    <br>
    <b>Hui Liu</b>, Zhan Shi, Jia-Chen Gu, Quan Liu, Si Wei, Xiaodan Zhu
    <br>
    <i>IJCAI 2020, full paper</i>
  </li>
  <font size="-1">
    [<a href="https://github.com/LayneIns/E2E-dialo-disentanglement" target="_blank">code</a>]
  </font>
  <br>

  <li>
    <b>
      <a href="https://www.aclweb.org/anthology/P19-1560/" target="_blank">Towards Explainable NLP: A Generative Explanation Framework for Text Classification</a>
    </b>
    <br>
    <b>Hui Liu</b>, Qingyu Yin, William Yang Wang 
    <br>
    <i>ACL 2019, long paper</i>
 </li>
  <!-- <div id="bib1" style="display:none">
  <blockquote>
  <pre class="bib-content">
    @inproceedings{liu-etal-2019-towards-explainable,
      title = {Towards Explainable NLP: A Generative Explanation Framework for Text Classification},
      author ={Liu, Hui  and Yin, Qingyu  and Wang, William Yang},
      booktitle = {Proceedings of the 57th Conference of the Association for Computational Linguistics},
      month = jul,
      year = {2019},
      address = {Florence, Italy},
      publisher = {Association for Computational Linguistics},
      url = {https://www.aclweb.org/anthology/P19-1560},
      pages = {5570--5581},
    }
  </pre>
  </blockquote>
  </div> -->
  <font size="-1">
    <!-- [<a href="javascript:copy(div1, bib1)">bib</a>]  -->
    [<a href="https://github.com/LayneIns/Generative-Explanation-Framework-for-Text-Classification" target="_blank">code</a>]</font>
  <!-- <div id="div1"></div> -->
  <br>

  <li> 
    <b>
      <a href="https://dl.acm.org/citation.cfm?id=3183370">QuoteRec: Toward Quote Recommendation for Writing</a></b><br> Jiwei Tan, Xiaojun Wan, <b>Hui Liu</b>, Jianguo Xiao 
    <br> 
    <i>ACM Transactions on Information Systems (TOIS), 2018</i>
  </li>
  <!-- <div id="bib0" style="display:none">
  <blockquote>
  <pre class="bib-content">
    @article{Tan:2018:QTQ:3146384.3183370,
      author = {Tan, Jiwei and Wan, Xiaojun and Liu, Hui and Xiao, Jianguo},
      title = {QuoteRec: Toward Quote Recommendation for Writing},
      journal = {ACM Trans. Inf. Syst.},
      issue_date = {April 2018},
      volume = {36},
      number = {3},
      month = mar,
      year = {2018},
      issn = {1046-8188},
      pages = {34:1--34:36},
      articleno = {34},
      numpages = {36},
      url = {http://doi.acm.org/10.1145/3183370},
      doi = {10.1145/3183370},
      acmid = {3183370},
      publisher = {ACM},
      address = {New York, NY, USA},
      keywords = {Deep learning, LSTM, document recommendation, quote recommendation},
    } 
  </pre>
  </blockquote>
  </div> -->
  <!-- <div id="div0"></div> -->
  </div>

  <div id="preprint-section">
  <h3 id="preprint">Preprint</h3>
  <li>
    <b>
      <a href="https://arxiv.org/abs/2507.07375" target="_blank">Bradley-Terry and Multi-Objective Reward Modeling Are Complementary</a> 
    </b>
    <br>
    Zhiwei Zhang, <b>Hui Liu</b>, Xiaomin Li, Zhenwei Dai, Jingying Zeng, Fali Wang, Minhua Lin, Ramraj Chandradevan, Zhen Li, Chen Luo, Xianfeng Tang, Qi He, Suhang Wang
    <br>
    <i>Manuscript, 2025</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2508.02669" target="_blank">MedVLThinker: Simple Baselines for Multimodal Medical Reasoning</a> 
    </b>
    <br>
    Xiaoke Huang, Juncheng Wu, <b>Hui Liu</b>, Xianfeng Tang, Yuyin Zhou
    <br>
    <i>Manuscript, 2025</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2506.02546" target="_blank">Attention Knows Whom to Trust: Attention-based Trust Management for LLM Multi-Agent Systems</a> 
    </b>
    <br>
    Pengfei He, Zhenwei Dai, Xianfeng Tang, Yue Xing, <b>Hui Liu</b>, Jingying Zeng, Qiankun Peng, Shrivats Agrawal, Samarth Varshney, Suhang Wang, Jiliang Tang, Qi He
    <br>
    <i>Manuscript, 2025</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2506.01245" target="_blank">Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS</a> 
    </b>
    <br>
    Pengfei He, Yue Xing, Shen Dong, Juanhui Li, Zhenwei Dai, Xianfeng Tang, <b>Hui Liu</b>, Han Xu, Zhen Xiang, Charu C. Aggarwal, Hui Liu
    <br>
    <i>Manuscript, 2025</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2505.18440" target="_blank">Efficient Long CoT Reasoning in Small Language Models</a> 
    </b>
    <br>
    Zhaoyang Wang, Jinqi Jiang, Tian Qiu, <b>Hui Liu</b>, Xianfeng Tang, Huaxiu Yao
    <br>
    <i>Manuscript, 2025</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2504.08202" target="_blank">Harnessing the Unseen: The Hidden Influence of Intrinsic Knowledge in Long-Context Language Models</a> 
    </b>
    <br>
    Yu Fu, Haz Sameen Shahgir, <b>Hui Liu</b>, Xianfeng Tang, Qi He, Yue Dong
    <br>
    <i>Manuscript, 2025</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2504.00869" target="_blank">m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning with Large Language Models</a> 
    </b>
    <br>
    Xiaoke Huang, Juncheng Wu, <b>Hui Liu</b>, Xianfeng Tang, Yuyin Zhou
    <br>
    <i>Manuscript, 2025</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2503.04830" target="_blank">Cite Before You Speak: Enhancing Context-Response Grounding in E-commerce Conversational LLM-Agents</a> 
    </b>
    <br>
    Jingying Zeng<sup>*</sup>, <b>Hui Liu</b><sup>*</sup>, Zhenwei Dai<sup>*</sup>, Xianfeng Tang, Chen Luo, Samarth Varshney, Zhen Li, Qi He
    <br>
    <i>Manuscript, 2025</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2502.18387" target="_blank">How Far are LLMs from Real Search? A Comprehensive Study on Efficiency, Completeness, and Inherent Capabilities</a> 
    </b>
    <br>
    Minhua Lin, <b>Hui Liu</b>, Xianfeng Tang, Jingying Zeng, Zhenwei Dai, Chen Luo, Zheng Li, Xiang Zhang, Qi He, Suhang Wang
    <br>
    <i>Manuscript, 2025</i>
  </li>
  <br>

  <li>
    <b>
      <a href="https://arxiv.org/abs/2412.12767" target="_blank">A Survey of Calibration Process for Black-Box LLMs</a> 
    </b>
    <br>
    Liangru Xie, <b>Hui Liu</b>, Jingying Zeng, Xianfeng Tang, Yan Han, Chen Luo, Jing Huang, Zhen Li, Suhang Wang, Qi He
    <br>
    <i>Manuscript, 2024</i>
  </li>
  </div>

</ol>


<a name="misc" class="disabled" style="color: inherit; text-decoration: none; pointer-events: none;"><h2 style="margin-top: 30px;"> Miscellaneous </h2></a>
<!-- <h2> Miscellaneous </h2></a> -->
<ul>
  <li> My name is Hui, a Mandarin Chinese syllable. You may pronounce it as "/ˈhuːei/".</li>
  <li> I was born in <a href="https://en.wikipedia.org/wiki/Ji%27an" target="_blank">Ji'an, China</a>, a city which has nurtured many notable people from the ancient. </li>
  <li> I am a photographer, and I believe taking a good photo requires the same effort and attention to detail as conducting thorough research. If you're in the Bay Area and want to look great in a photo (or just want to discuss about research and AI), hit me up!
</ul>
<!-- <hr> -->

<!-- <p>
  Last updated: 05/2025</span>
</p> -->

                 
</body>
</html>

